{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bc4144-0ad1-4bc3-914c-96fa1d66dc86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# A brief introduction to reinforcements learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb285d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## so what is reinforcements learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3ef9a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward (wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17045e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Before understend reinforcement learning in computer, we need to understand who reinforcement learning work in humen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fba263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### so lets take a look on the first steps of an baby (humen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb905fb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fcda1e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![hello](stuff\\baby_pic.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb4239",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lets ask some questions \n",
    "1. who is our agent (who is \"learn\") ?\n",
    "2. what is our environment ? \n",
    "3. what is mother rule ? \n",
    "4. what is the reward ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf337f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This the baby is sucss in the first time to walk ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f6845",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### NO , The baby needs to study for a full time until he can walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69b0fff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/ZEfvYzJKZdU\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x25e9bd91550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## python code to load the video\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('ZEfvYzJKZdU', width=800, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b608c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lets go back to renforsment learnig in computer and try to defint that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19273c41-c7e5-487d-9490-260b718b6951",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The reinforcement learning is based on learning from trial and error that takes place in a series of interactions between a learning agent (software component or robot) and his environment that is represented as sensory information available to the learning agent. In each such interaction, the agent receives information from his environment regarding the correct situation and chooses to take action to distribute actions available to him in need of the current action policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417db44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ok Let's see that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b980d-7534-4dc4-875a-0add9f5edd9e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](stuff\\agent_pic.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c40f3-d98c-439c-8a24-831b8e1cd2c7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Ok we learn computer science, it's time to code our agent !!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8d8ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What is gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08072db6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gym is a toolkit for developing and comparing reinforcement learning algorithms. It makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765b9931-3fb6-4e62-8854-b7758a15fe7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# lodaing the enviorment\n",
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a97d3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "observation (object): an environment-specific object representing your observation of the environment. For example, pixel data from a camera, joint angles and joint velocities of a robot, or the board state in a board game.\n",
    "\n",
    "reward (float): amount of reward achieved by the previous action. The scale varies between environments, but the goal is always to increase your total reward.\n",
    "\n",
    "done (boolean): whether it’s time to reset the environment again. Most (but not all) tasks are divided up into well-defined episodes, and done being True indicates the episode has terminated. (For example, perhaps the pole tipped too far, or you lost your last life.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19cccf1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# lodaing the enviorment\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "for i_episode in range(3):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        action = 0 #\n",
    "        # print(\"I did step {0} in epsidoe {1}\".format(t,i_episode))\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "    # print(\"episode {0} finished\".format(i_episode)) \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6baadb6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space:  Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)\n",
      "Action space:  Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "# This tells us that the state space represents a 2-dimensional box, \n",
    "# so each state observation is a vector of 2 (float) values, and that the action space comprises three discrete actions\n",
    "# (which is what we already knew)\n",
    "print(\"State space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c53a44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2  -0.07]\n",
      "[0.6  0.07]\n"
     ]
    }
   ],
   "source": [
    "# From this, we can see that the first element of the state vector (representing the cart’s position) \n",
    "# can take on any value in the range -1.2 to 0.6, while the second element (representing the cart’s velocity) \n",
    "# can take on any value in the range -0.07 to 0.07.\n",
    "print(env.observation_space.low)\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e584e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53286325  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# The initial state of an environment is returned when you reset the environment:\n",
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1decdc7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.53179378,  0.00106947]), -1.0, False, {})\n"
     ]
    }
   ],
   "source": [
    "# To take an action (for example, a = 2), \n",
    "# it is necessary to “step forward” the environment by that action using the step() method. \n",
    "# This returns a 4-ple giving \n",
    "# the new state\n",
    "# reward \n",
    "# a Boolean indicating whether or not the episode has terminated (due to the goal being reached or 200 steps having elapsed)\n",
    "# any additional information (this is always empty for this problem)\n",
    "print(env.step(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1cabe7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reinforcements learning algoritem\n",
    "In the first article in this series, we went through the Q-learning algorithm in detail. When going though this algorithm, we assumed a one-dimensional state space, so our goal was to find the optimal Q table, Q(s,a).\n",
    "In this problem, since we our dealing with a two-dimensional state space, we replace Q(s, a) with Q(s1, s2, a), but other than that, the Q-learning algorithm remains more or less the same.\n",
    "To recap, the algorithm is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ff279",
   "metadata": {},
   "source": [
    "## 1. Initialize Q(s1, s2, a) by setting all of the elements equal to small random values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bd6f088",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 15, 3)\n",
      "[[ 0.81848682  0.17396768 -0.47633005]\n",
      " [-0.75428578 -0.11881647  0.10337941]\n",
      " [ 0.10193625 -0.55172003 -0.30287127]\n",
      " [-0.71712165 -0.68561265  0.61685795]\n",
      " [ 0.4246616  -0.21030546 -0.89532708]\n",
      " [ 0.44326869  0.35153449  0.79015444]\n",
      " [-0.0263188   0.01852644  0.93518096]\n",
      " [-0.62668267 -0.31397361 -0.45392466]\n",
      " [-0.43577562 -0.28674825 -0.31688229]\n",
      " [ 0.92218227  0.79102458 -0.45156111]\n",
      " [-0.31168809  0.42213902  0.51658087]\n",
      " [ 0.66601045 -0.90401472 -0.32583892]\n",
      " [-0.68305007 -0.62872709  0.45368653]\n",
      " [-0.81377992 -0.86939443  0.00653492]\n",
      " [ 0.54104462 -0.35645124 -0.91737307]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_states = (env.observation_space.high - env.observation_space.low)*\\\n",
    "                    np.array([10, 100])\n",
    "num_states = np.round(num_states, 0).astype(int) + 1\n",
    "    \n",
    "    \n",
    "# Initialize Q table\n",
    "Q = np.random.uniform(low = -1, high = 1, \n",
    "                          size = (num_states[0], num_states[1], \n",
    "                                  env.action_space.n))\n",
    "print(Q.shape)\n",
    "print(Q[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a1368",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](stuff\\3_dim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae76ff",
   "metadata": {},
   "source": [
    "## 2. Observe the current state, (s1, s2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896640e6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a10e205b8eec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Discretize state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstate_adj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstate_adj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_adj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "# Discretize state\n",
    "state_adj = (state - env.observation_space.low)*np.array([10, 100])\n",
    "state_adj = np.round(state_adj, 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42434f9",
   "metadata": {},
   "source": [
    "![](stuff\\init_new_dim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a42c8",
   "metadata": {},
   "source": [
    "## 3. Based on the exploration strategy, choose an action to take, a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a19316e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-e943320ff3f7>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-e943320ff3f7>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Determine next action - epsilon greedy strategy\n",
    "if np.random.random() < 1 - epsilon:\n",
    "    action = np.argmax(Q[state_adj[0], state_adj[1]]) \n",
    "    else:\n",
    "    action = np.random.randint(0, env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c012cf",
   "metadata": {},
   "source": [
    "![](stuff\\choose_where_to_go_new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2b3e8",
   "metadata": {},
   "source": [
    "## 4. Take action a and observe the resulting reward, r, and the new state of the environment, (s1’, s2’);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "041d1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get next state and reward\n",
    "next_state, reward, done, info = env.step(action)        \n",
    "# Discretize next_state\n",
    "next_state_adj = (next_state - env.observation_space.low)*np.array([10, 100])\n",
    "next_state_adj = np.round(next_state, 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66620ee1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](stuff\\next_state.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb008a18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Update Q(s1, s2, a) based on the update rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow for terminal states         \n",
    "if done and next_state[0] >= 0.5:\n",
    "    Q[state_adj[0], state_adj[1], action] = reward\n",
    "                \n",
    "# Adjust Q value for current state\n",
    "else:\n",
    "    delta = learning*(reward + discount*np.max(Q[next_state_adj[0], next_state_adj[1]]) - Q[state_adj[0], state_adj[1],action])\n",
    "    Q[state_adj[0], state_adj[1],action] += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4b389",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](stuff\\save_pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bfc06a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def QLearning(env, learning, discount, epsilon, min_eps, episodes):\n",
    "    # Determine size of discretized state space\n",
    "    num_states = (env.observation_space.high - env.observation_space.low)*\\\n",
    "                    np.array([10, 100])\n",
    "    num_states = np.round(num_states, 0).astype(int) + 1\n",
    "    \n",
    "    # Initialize Q table\n",
    "    Q = np.random.uniform(low = -1, high = 1, \n",
    "                          size = (num_states[0], num_states[1], \n",
    "                                  env.action_space.n))\n",
    "    \n",
    "    # Initialize variables to track rewards\n",
    "    reward_list = []\n",
    "    ave_reward_list = []\n",
    "    \n",
    "    # Calculate episodic reduction in epsilon\n",
    "    reduction = (epsilon - min_eps)/episodes\n",
    "    \n",
    "    # Run Q learning algorithm\n",
    "    for i in range(episodes):\n",
    "        # Initialize parameters\n",
    "        done = False\n",
    "        tot_reward, reward = 0,0\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Discretize state\n",
    "        state_adj = (state - env.observation_space.low)*np.array([10, 100])\n",
    "        state_adj = np.round(state_adj, 0).astype(int)\n",
    "    \n",
    "        while done != True:   \n",
    "            # Render environment for last five episodes\n",
    "            if i >= (episodes - 20):\n",
    "                env.render()\n",
    "                \n",
    "            # Determine next action - epsilon greedy strategy\n",
    "            if np.random.random() < 1 - epsilon:\n",
    "                action = np.argmax(Q[state_adj[0], state_adj[1]]) \n",
    "            else:\n",
    "                action = np.random.randint(0, env.action_space.n)\n",
    "                \n",
    "            # Get next state and reward\n",
    "            state2, reward, done, info = env.step(action) \n",
    "            \n",
    "            # Discretize state2\n",
    "            state2_adj = (state2 - env.observation_space.low)*np.array([10, 100])\n",
    "            state2_adj = np.round(state2_adj, 0).astype(int)\n",
    "            \n",
    "            #Allow for terminal states\n",
    "            if done and state2[0] >= 0.5:\n",
    "                Q[state_adj[0], state_adj[1], action] = reward\n",
    "                \n",
    "            # Adjust Q value for current state\n",
    "            else:\n",
    "                delta = learning*(reward + \n",
    "                                 discount*np.max(Q[state2_adj[0], \n",
    "                                                   state2_adj[1]]) - \n",
    "                                 Q[state_adj[0], state_adj[1],action])\n",
    "                Q[state_adj[0], state_adj[1],action] += delta\n",
    "                                     \n",
    "            # Update variables\n",
    "            tot_reward += reward\n",
    "            state_adj = state2_adj\n",
    "        \n",
    "        # Decay epsilon\n",
    "        if epsilon > min_eps:\n",
    "            epsilon -= reduction\n",
    "        \n",
    "        # Track rewards\n",
    "        reward_list.append(tot_reward)\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            ave_reward = np.mean(reward_list)\n",
    "            ave_reward_list.append(ave_reward)\n",
    "            reward_list = []\n",
    "            \n",
    "        if (i+1) % 100 == 0:    \n",
    "            print('Episode {} Average Reward: {}'.format(i+1, ave_reward))\n",
    "            \n",
    "    env.close()\n",
    "    \n",
    "    return ave_reward_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccd94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee1785e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 Average Reward: -200.0\n",
      "Episode 200 Average Reward: -200.0\n",
      "Episode 300 Average Reward: -200.0\n",
      "Episode 400 Average Reward: -200.0\n",
      "Episode 500 Average Reward: -200.0\n",
      "Episode 600 Average Reward: -200.0\n",
      "Episode 700 Average Reward: -200.0\n",
      "Episode 800 Average Reward: -200.0\n",
      "Episode 900 Average Reward: -200.0\n",
      "Episode 1000 Average Reward: -200.0\n",
      "Episode 1100 Average Reward: -200.0\n",
      "Episode 1200 Average Reward: -200.0\n",
      "Episode 1300 Average Reward: -200.0\n",
      "Episode 1400 Average Reward: -200.0\n",
      "Episode 1500 Average Reward: -200.0\n",
      "Episode 1600 Average Reward: -200.0\n",
      "Episode 1700 Average Reward: -200.0\n",
      "Episode 1800 Average Reward: -200.0\n",
      "Episode 1900 Average Reward: -200.0\n",
      "Episode 2000 Average Reward: -200.0\n",
      "Episode 2100 Average Reward: -200.0\n",
      "Episode 2200 Average Reward: -200.0\n",
      "Episode 2300 Average Reward: -200.0\n",
      "Episode 2400 Average Reward: -200.0\n",
      "Episode 2500 Average Reward: -200.0\n",
      "Episode 2600 Average Reward: -200.0\n",
      "Episode 2700 Average Reward: -200.0\n",
      "Episode 2800 Average Reward: -200.0\n",
      "Episode 2900 Average Reward: -199.97\n",
      "Episode 3000 Average Reward: -200.0\n",
      "Episode 3100 Average Reward: -199.98\n",
      "Episode 3200 Average Reward: -200.0\n",
      "Episode 3300 Average Reward: -200.0\n",
      "Episode 3400 Average Reward: -199.95\n",
      "Episode 3500 Average Reward: -200.0\n",
      "Episode 3600 Average Reward: -199.7\n",
      "Episode 3700 Average Reward: -199.94\n",
      "Episode 3800 Average Reward: -199.09\n",
      "Episode 3900 Average Reward: -198.05\n",
      "Episode 4000 Average Reward: -195.78\n",
      "Episode 4100 Average Reward: -196.29\n",
      "Episode 4200 Average Reward: -195.51\n",
      "Episode 4300 Average Reward: -199.12\n",
      "Episode 4400 Average Reward: -193.72\n",
      "Episode 4500 Average Reward: -196.16\n",
      "Episode 4600 Average Reward: -194.96\n",
      "Episode 4700 Average Reward: -190.37\n",
      "Episode 4800 Average Reward: -189.74\n",
      "Episode 4900 Average Reward: -197.88\n",
      "Episode 5000 Average Reward: -194.46\n"
     ]
    }
   ],
   "source": [
    "# Run Q-learning algorithm\n",
    "# (env, learning, discount, epsilon, episodes):\n",
    "rewards = QLearning(env, 0.2, 0.9, 0.8, 0, 5000)\n",
    "\n",
    "# Plot Rewards\n",
    "plt.plot(100*(np.arange(len(rewards)) + 1), rewards)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Average Reward vs Episodes')\n",
    "plt.savefig('rewards.jpg')     \n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d8b00fd6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 15, 3)\n",
      "(3, 15, 19)\n",
      "(15, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "print(Q.shape)\n",
    "new_Q = np.transpose(Q, (2, 1, 0))\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "print(new_Q.shape)\n",
    "print(new_Q[0].shape)\n",
    "plt.imshow(new_Q[0], interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "65727312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "i=0\n",
    "fig, axes = plt.subplots(ncols=3)\n",
    "for ax in axes.flat:\n",
    "    im = ax.imshow(new_Q[i],cmap=\"inferno\")\n",
    "    i+=1\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "05c22211",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "fig, axes = plt.subplots(ncols=3)\n",
    "for i in range(100):\n",
    "    j = 0\n",
    "    for ax in axes.flat:             \n",
    "        \n",
    "        im = ax.imshow(new_Q[j], cmap='inferno')\n",
    "        j+=1\n",
    "    # temp = new_Q[0]\n",
    "    # im1 = ax.imshow(temp, cmap='coolwarm', aspect='equal')\n",
    "    if i == 0:\n",
    "        cbar = plt.colorbar(im)\n",
    "    else:\n",
    "        cbar.update_normal(im)\n",
    "    new_Q[0][0][9]+=0.1\n",
    "    plt.pause(0.00000001)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# fig1 = plt.figure()\n",
    "# ax = fig1.add_subplot(111)\n",
    "# for i in range(100):\n",
    "#     temp = np.random.normal(0, 1, size=(10,10))\n",
    "#     im1 = ax.imshow(temp, cmap='coolwarm', aspect='equal')\n",
    "#     if i == 0:\n",
    "#         cbar = plt.colorbar(im1)\n",
    "#     else:\n",
    "#         cbar.update_normal(im1)\n",
    "#     plt.pause(0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae908d13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3)\n",
    "                     \n",
    "def QLearning_plot(env, learning, discount, epsilon, min_eps, episodes):\n",
    "    # Initialize Q table\n",
    "        # Determine size of discretized state space\n",
    "    num_states = (env.observation_space.high - env.observation_space.low)*\\\n",
    "                    np.array([10, 100])\n",
    "    num_states = np.round(num_states, 0).astype(int) + 1\n",
    "    Q = np.random.uniform(low = 1, high = 1, \n",
    "                          size = (num_states[0], num_states[1], \n",
    "                                  env.action_space.n)) \n",
    "\n",
    "    \n",
    "    # Initialize variables to track rewards\n",
    "    reward_list = []\n",
    "    ave_reward_list = []\n",
    "    \n",
    "    # Calculate episodic reduction in epsilon\n",
    "    reduction = (epsilon - min_eps)/episodes\n",
    "    \n",
    "    # Run Q learning algorithm\n",
    "    for i in range(episodes):\n",
    "        # Initialize parameters\n",
    "        done = False\n",
    "        tot_reward, reward = 0,0\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Discretize state\n",
    "        state_adj = (state - env.observation_space.low)*np.array([10, 10])\n",
    "        state_adj = np.round(state_adj, 0).astype(int)\n",
    "    \n",
    "        while done != True:   \n",
    "            # Render environment for last five episodes\n",
    "            if i >= (episodes - 20):\n",
    "               env.render()\n",
    "                \n",
    "            # Determine next action - epsilon greedy strategy\n",
    "            if np.random.random() < 1 - epsilon:\n",
    "                action = np.argmax(Q[state_adj[0], state_adj[1]]) \n",
    "            else:\n",
    "                action = np.random.randint(0, env.action_space.n)\n",
    "                \n",
    "            # Get next state and reward\n",
    "            state2, reward, done, info = env.step(action) \n",
    "            \n",
    "            # Discretize state2\n",
    "            state2_adj = (state2 - env.observation_space.low)*np.array([10, 100])\n",
    "            state2_adj = np.round(state2_adj, 0).astype(int)\n",
    "            \n",
    "            # get to the flag\n",
    "            if done and state2[0] >= 0.5:\n",
    "                Q[state_adj[0], state_adj[1], action] = reward\n",
    "                \n",
    "            # Adjust Q value for current state\n",
    "            else:\n",
    "                delta = learning*(reward + \n",
    "                                 discount*np.max(Q[state2_adj[0], \n",
    "                                                   state2_adj[1]]) - \n",
    "                                 Q[state_adj[0], state_adj[1],action])\n",
    "                Q[state_adj[0], state_adj[1],action] += delta\n",
    "                                     \n",
    "            # Update variables\n",
    "            tot_reward += reward\n",
    "            state_adj = state2_adj\n",
    "        \n",
    "        # Decay epsilon\n",
    "        if epsilon > min_eps:\n",
    "            epsilon -= reduction\n",
    "        \n",
    "        # Track rewards\n",
    "        reward_list.append(tot_reward)\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            ave_reward = np.mean(reward_list)\n",
    "            ave_reward_list.append(ave_reward)\n",
    "            reward_list = []\n",
    "            \n",
    "        if (i+1) % 100 == 0:    \n",
    "            print('Episode {} Average Reward: {}'.format(i+1, ave_reward))\n",
    "\n",
    "        if i == 0 or (i+1) % 100 ==0:\n",
    "            Q_plot = np.transpose(Q, (2, 1, 0))\n",
    "            j = 0\n",
    "            for ax in axes.flat:   \n",
    "                im = ax.imshow(Q_plot[j], cmap='inferno', aspect='equal')\n",
    "                ax.invert_yaxis()\n",
    "                j+=1\n",
    "            if i == 0:\n",
    "                k = 0\n",
    "                for ax in axes.flat:\n",
    "                    ax.invert_yaxis()\n",
    "                    ax.set(xlabel='car’s position', ylabel='car’s velocity', title='action {0}'.\n",
    "                              format(k))  \n",
    "                    k+=1\n",
    "                cbar = plt.colorbar(im)\n",
    "            else:\n",
    "                cbar.update_normal(im)\n",
    "            plt.pause(0.00000001)\n",
    "    env.close()\n",
    "    \n",
    "    return Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4095b435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 Average Reward: -200.0\n",
      "Episode 200 Average Reward: -200.0\n",
      "Episode 300 Average Reward: -200.0\n",
      "Episode 400 Average Reward: -200.0\n",
      "Episode 500 Average Reward: -200.0\n",
      "Episode 600 Average Reward: -200.0\n",
      "Episode 700 Average Reward: -200.0\n",
      "Episode 800 Average Reward: -200.0\n",
      "Episode 900 Average Reward: -200.0\n",
      "Episode 1000 Average Reward: -200.0\n",
      "Episode 1100 Average Reward: -200.0\n",
      "Episode 1200 Average Reward: -200.0\n",
      "Episode 1300 Average Reward: -200.0\n",
      "Episode 1400 Average Reward: -200.0\n",
      "Episode 1500 Average Reward: -200.0\n",
      "Episode 1600 Average Reward: -200.0\n",
      "Episode 1700 Average Reward: -200.0\n",
      "Episode 1800 Average Reward: -200.0\n",
      "Episode 1900 Average Reward: -200.0\n",
      "Episode 2000 Average Reward: -200.0\n",
      "Episode 2100 Average Reward: -200.0\n",
      "Episode 2200 Average Reward: -200.0\n",
      "Episode 2300 Average Reward: -200.0\n",
      "Episode 2400 Average Reward: -200.0\n",
      "Episode 2500 Average Reward: -200.0\n",
      "Episode 2600 Average Reward: -200.0\n",
      "Episode 2700 Average Reward: -200.0\n",
      "Episode 2800 Average Reward: -199.71\n",
      "Episode 2900 Average Reward: -200.0\n",
      "Episode 3000 Average Reward: -200.0\n",
      "Episode 3100 Average Reward: -200.0\n",
      "Episode 3200 Average Reward: -200.0\n",
      "Episode 3300 Average Reward: -200.0\n",
      "Episode 3400 Average Reward: -200.0\n",
      "Episode 3500 Average Reward: -198.8\n",
      "Episode 3600 Average Reward: -199.65\n",
      "Episode 3700 Average Reward: -196.8\n",
      "Episode 3800 Average Reward: -193.5\n",
      "Episode 3900 Average Reward: -196.82\n",
      "Episode 4000 Average Reward: -199.02\n",
      "Episode 4100 Average Reward: -199.67\n",
      "Episode 4200 Average Reward: -196.18\n",
      "Episode 4300 Average Reward: -196.63\n",
      "Episode 4400 Average Reward: -193.19\n",
      "Episode 4500 Average Reward: -192.23\n",
      "Episode 4600 Average Reward: -196.43\n",
      "Episode 4700 Average Reward: -197.14\n",
      "Episode 4800 Average Reward: -186.62\n",
      "Episode 4900 Average Reward: -194.87\n",
      "Episode 5000 Average Reward: -175.67\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# lodaing the enviorment\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "Q_table = QLearning_plot(env, 0.2, 0.9, 0.8, 0, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04691a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    env = gym.make(\"MountainCar-v0\")\n",
    "    done = False\n",
    "    action = 0\n",
    "    # Run Q learning algorithm\n",
    "    for i in range(0,3):\n",
    "        # Initialize parameters\n",
    "        is_done = False\n",
    "        state = env.reset()\n",
    "        state_adj = (state - env.observation_space.low)*np.array([10, 10])\n",
    "        state_adj = np.round(state_adj, 0).astype(int)\n",
    "        while is_done != True:\n",
    "            env.render()\n",
    "            action = np.argmax(Q_table[state_adj[0], state_adj[1]]) \n",
    "            state2, reward, done, info = env.step(action) \n",
    "            # get to the flag\n",
    "            if done and state2[0] >= 0.5:\n",
    "                print(state2[0])\n",
    "                is_done = True\n",
    "            # Discretize state2\n",
    "            state2_adj = (state2 - env.observation_space.low)*np.array([10, 100])\n",
    "            state2_adj = np.round(state2_adj, 0).astype(int)\n",
    "            state_adj = state2_adj\n",
    "            # print(done)\n",
    "        print(\"finish!!\")\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "304b8523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5094274190567265\n",
      "finish!!\n",
      "0.5094274190567265\n",
      "finish!!\n",
      "0.5097561367690611\n",
      "finish!!\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ba9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
